## Introduction

- https://en.wikipedia.org/wiki/Michael_Stonebraker

Vector databases i.e. Elastic, Spark, e.t.c

- Maybe similar / identical to vector databases mentioned in CS432 (Introduction to Data Science)

**Contact info: dong.deng@rutgers.edu**

---

- While a database may simply store data, a Database Management System entails more functionality.

DBMS collect and store interrelated data AND contains a set of programs used to access 
the data AND provide a way to store and retrieve (query) the data.

Examples of common applications of databases: Online libraries, digital storefronts, reccomendation systems (Netflix, social media),
every smartphone or digital device, application managers / password managers.

- Databases are explicitly used in industries such as Sales, Accounting, HR, Manufacturing, Finance, e.t.c

**Data is digital gold**

---

### Evolution of Database Systems

Early DBMS systems had the following attributes

- Databases were responsibles for managing simple, precisely formatted, and structured data. Ex. University records

- Had limited direct interaction, the end users don't access (query) the database directly. Instead they ask some staff, and the staff accesses the database.

- The products of this indirect interaction were reports, statements, and roles such as agents (i.e bank tellers, airline reservation agents).

Modern DMBS systems prioritize more flexible and direct end user interaction with databases.

- **Volume, Velocity, Variety, Veracity**

- We deal with large amounts of data that is constantly and quickly changing. The data may be in various formats (text, images, audio, video, e.t.c). Perhaps as a consequence of the prior three attributes the data is more prone to duplication, errors, or is generally "cleaned" before usage.

- ATMs are arguably one of the first examples of direct database interaction between end users and the data itself.

- Voice automated systems (calling the bank to acquire information or change database information).

- The Internet allows for cleaner UIs to effectively conceal and take care of database access details without little user effort (i.e. enter a username and password).

- **Most if not all online services utilize underlying databases to record activity and transaction details that occur from the end user!**

---

### Workloads

- OLTP (Online Transaction Processing) vs OLAP (Online Analytics Processing)

| OLTP | OLAP |
| ---- | ---- |
| large users access the database frequently and concurrently | analyzation of large amount of data but not by users, but by employee or organization |
| each user updates a relatively small amount of data per transaction | usually involves reading large amounts of data |
| this is the typical workload in the early stages of an enterprise | little to no updates occur on the data |
| Often used in live / ongoing services such as banking | Often used for and within predictive models (i.e. data mining, ML, AI, live / adaptive training) |
| ex. inventory tracking on Amazon | ex. Predict the probability of paying back a loan based on past payments and purchases |


Note: To me, SAP seems like a company that specializes in OLAP workloads (could be wrong)

---

### Why not use the naive solution (excel / csv files)?

Then just create custom scripts and programs to access the programs

**There are several disadvantages to this naive solution**

- **Information duplication may appear across different files (i.e. a double major student in various college department tables)**

$\rarr$ **Data duplication results in higher storage costs and potential inconsistency**

- **Data access can be cumbersome, you may need to write new code for new types or specifications of queries.**

- **Data isolation: data may be stored in different formats (which is a pain if you wanna retrieve programs)**

$\rarr$ **We want to enforce integrity constraints on the data (i.e. balance cannot be negative, SSN must be 9 digits e.t.c.). These constraints can be easily broken in the context of most programs.**

- **Atomicity of updates: Failures may leave the database with partial updats (which are unintended and result in inconsistences)**

To elaborate on the previous point, all operations in an ideal DB should either happen or not happen,
and any partial updates caused by system failure should be rolled back.

Ex. A bank transfer should fully transfer an ammount or nothing at all (esp in the case of system failure).

- **Concurrent accessing on a database can lead to inconsistent updates (think of threads and the importance of threaded access from CS214).**

- **In rudimentary systems it is hard to provide various types of users limited or customized access to the data.**

Ex. Payroll personnel should not be able to access academic records, but the ability to enforce this is complex with simple file systems.

These problems were tackled over time in the 1960s and 70s between the transition between basic file management systems and DBMSs.

---

### Data Abstraction

Modern databases manage very complex data, instead of getting overwhelmed with it all it is better to abstract it.

- The concept of abstraction is not unique to DBMSs and in general as a programmer it is not necessary to know the inner workings of the code that is executed in its simplest form.

**Abstraction makes coding human friendly!**

- **DBMSs similarly hide more complex details of data storage and maintainence.**

**A data model is a collection of tools for describing the data, data relationships, consistency constraints, and more!**

Ex: Relational model, XML, JSON, Hierarchy Model, Network Model.

**We focus on the Relational Model: data stored in tables.**


---

### Levels of Abstraction

From the deepest level to the surface they are:

1. Physical Level

Physical design involves working within our chosen DBMS such as Oracle, MySQL, e.t.c. and identifying ways in which we can optimize our original database design by using tools available within the software.

- At this stage we consider implementing concepts such as **indexing, clustering, and replication**.

Note that this stage may substanially change the schema that we created from the previous steps. This is totally fine as long as its well documented and tested for accuracy.

- **These details are often hidden from programmers and end users.**

2. Logical Level

At this level we choose an actual database management system (**DBMS**) to implement the designed ER model. In our case we will only consider relational databases (although other types do exist and are increasingly popular). **So the end goal is to convert the ER schema into a relational database schema. The product is the conceptual or logical schema.**

- Describes what data is stored and the relationships between data

**Physical Data Independence: changes in the physical level should not influence the design of the logical level (changing your database provider or your hardware should not force you to change your logical structures).**

- Users at this level do not need to understand the details of the physical level.

- Database admins work at this level

3. View Level

- **Views are tailored to the users accessing the database.**

- Describes only a part of the DB that is of concern to the particular user.

---

### Tasks of a Database Administrator

DBAs are responsible for:

- Creating the initial database schema.
- Defining how data is stored and accessed. (Ex. Can a new table be created to speed up access?)
- Schema and physical-organizaation modification. (ex. from transitions from OLAP to OTAP workloads)
- Granting of authorization for data access.
- Routine maintenance
- Periodically backing up the database
- Ensuring that enough disk space available for normal operations and upgrading disk space as required.
- Monitoring jobs that are running on the database.

Damn thats a lot :smile:

---

Database Architecture Diagram

To be included

---

https://learn.microsoft.com/en-us/sharepoint/dev/general-development/fast-query-language-fql-syntax-reference


